{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "\n",
    "- update psychopy_presentations/moving_hand with our own images/prompts\n",
    "- find out why command in step 2 does not work\n",
    "- update steps 4+\n",
    "\n",
    "DONE:\n",
    "\n",
    "- update steps 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": true
   },
   "outputs": [],
   "source": [
    "from muselsl import stream, view, record\n",
    "from multiprocessing import Process\n",
    "from mne import Epochs, find_events\n",
    "from time import time, strftime, gmtime\n",
    "import os\n",
    "import utils\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update these variables to incorporate different motions/signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific motions\n",
    "from psychopy_presentations import moving_hand\n",
    "\n",
    "# name of the folder in data to put the .csv files in\n",
    "# folder will be placed inside the data folder\n",
    "motion_type = \"moving_hand\"\n",
    "\n",
    "# name of the function that presents images/prompts using psychopy\n",
    "motion_function = moving_hand.present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update these parameters to define the length of the experiment and the subject name/session number of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# parameters for the experiment \n",
    "duration = 10 # in seconds. 120 is recommended\n",
    "subject = 1 # unique id for each participant\n",
    "session = 1 # represents a data collection session. Multiple trials can be performed for each session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Connect to an EEG Device\n",
    "\n",
    "    - Open BlueMuse\n",
    "    - Connect to Muse\n",
    "    - Start Streaming\n",
    "    - Put the Muse on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply the EEG Device and Wait for Signal Quality to Stabilize\n",
    "\n",
    "The numbers on the side of the graph indicate the variance of the signal. Wait until this decreases below 10 for all electrodes before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On Windows, you may need to replace this with the command %matplotlib tk\n",
    "%matplotlib\n",
    "\n",
    "#view(version = 2) # does not respond for some reason. use muselsl view --version 2 on cmd instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Experiment\n",
    "\n",
    "Seat the subject in front of the computer and run the following cell to run a single trial of the experiment. Each experiment will create a .csv file in the `data` folder that has `duration` amount of seconds of EEG data, which will have multiple events depending on the psychopy presentation function.\n",
    "\n",
    "In order to maximize the possibility of success, participants should take the experiment in a quiet environment and do their best to minimize movement that might contaminate the signal. With their jaw and face relaxed, subjects should focus on the stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "recording_path = os.path.join(\".\", \"data\", motion_type, \n",
    "                              \"subject_\" + str(subject), \n",
    "                              \"session_\" + str(session), \n",
    "                              (\"recording_%s.csv\" % strftime(\"%Y-%m-%d-%H.%M.%S\", gmtime())) + \".csv\")\n",
    "\n",
    "stimulus = Process(target=motion_function, args=(duration,))\n",
    "recording = Process(target=record, args=(duration, recording_path))\n",
    "\n",
    "stimulus.start()\n",
    "recording.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat Data Collection 3-6 times\n",
    "\n",
    "Visualizing ERPs requires averaging the EEG response over many different rounds of stimulus presentation. Depending on experimental conditions, this may require as little as one two minute trial or as many as 6. We recommend repeating the above experiment 3-6 times before proceeding. \n",
    "\n",
    "Make sure to take breaks, though! Inattention, fatigue, and distraction will decrease the quality of event-related potentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## Step 4: Prepare the Data for Analysis\n",
    "\n",
    "Once a suitable data set has been collected, it is now time to analyze the data and see if we can identify the N170\n",
    "\n",
    "\n",
    "### Load data into MNE objects\n",
    "\n",
    "[MNE](https://martinos.org/mne/stable/index.html) is a very powerful Python library for analyzing EEG data. It provides helpful functions for performing key tasks such as filtering EEG data, rejecting artifacts, and grouping EEG data into chunks (epochs).\n",
    "\n",
    "The first step to using MNE is to read the data we've collected into an MNE `Raw` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = utils.load_data('./data/' + motion_type, sfreq=256., \n",
    "                      subject_nb = subject, session_nb = session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Power Spectrum\n",
    "\n",
    "Plotting the power spectral density (PSD) of our dataset will give us a glimpse at the different frequencies that are present. We won't be able to see the P300 in the PSD, but it will give us an impression of how noisy our data was. A very noisy or flat PSD may represent poor signal quality at certain electrodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "raw.plot_psd();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This PSD looks good. There is a tremendous peak at 50hz and it's harmonic at 100hz. You can tell this dataset was collected in Europe because of the 50hz line noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Most ERP components are composed of lower frequency fluctuations in the EEG signal. Thus, we can filter out all frequencies between 1 and 30 hz in order to increase our ability to detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(1,30, method='iir')\n",
    "raw.plot_psd(fmin=1, fmax=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This PSD looks great. The AF8 electrode (Front right; light green) seems to have some noise in the signal, but the TP9 and TP10 electrodes (red and black) look great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching\n",
    "\n",
    "Next, we will chunk (epoch) the data into segments representing the data 100ms before to 800ms after each stimulus. No baseline correction is needed (signal is bandpass filtered) and we will reject every epoch where the amplitude of the signal exceeded 75 uV, which should most eye blinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = find_events(raw)\n",
    "event_id = {'Non-Target': 1, 'Target': 2}\n",
    "\n",
    "epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                tmin=-0.1, tmax=0.8, baseline=None,\n",
    "                reject={'eeg': 100e-6}, preload=True, \n",
    "                verbose=False, picks=[0,1,2,3])\n",
    "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample drop % is an important metric representing how noisy our data set was. If this is greater than 20%, consider ensuring that signal variances is very low in the raw EEG viewer and collecting more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze the Data\n",
    "\n",
    "Finally, we can now analyze our results by averaging the epochs that occured during the different stimuli and looking for differences in the waveform\n",
    "\n",
    "\n",
    "### Epoch average\n",
    "\n",
    "With our `plot_conditions` utility function, we can plot the average ERP for all electrodes for both conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "conditions = OrderedDict()\n",
    "conditions['Non-target'] = [1]\n",
    "conditions['Target'] = [2]\n",
    "\n",
    "fig, ax = utils.plot_conditions(epochs, conditions=conditions, \n",
    "                                ci=97.5, n_boot=1000, title='',\n",
    "                                diff_waveform=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a beautiful negative deflection in the EEG around 350ms after presentation of Target stimuli. The fact that it's occuring ~50ms later than expected is probably due to delay introduced by transmitting the data over bluetooth.\n",
    "\n",
    "But wait, isn't this supposed to be a positive ERP? Well, yes, but the Muse's reference electrode is in a different location than traditional EEG systems (at the very front of the forehead instead of the top of the head or near the ear). Because of the location of the source of the P300 signal in the brain, this means that the direction of the P300 potential is inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding the N170\n",
    "\n",
    "Next, we will use 4 different machine learning pipelines to classify the P300 based on the data we collected.\n",
    "\n",
    "- **Vect + LR** :  Vectorization of the trial + Logistic Regression. This can be considered the standard decoding pipeline for MEG / EEG.\n",
    "- **Vect + RegLDA** :  Vectorization of the trial + Regularized LDA. This one is very commonly used in P300 BCIs. It can outperform the previous one but become unusable if the number of dimension is too high.\n",
    "- **ERPCov + TS**: ErpCovariance + Tangent space mapping. One of the most reliable Riemannian geometry-based pipeline.\n",
    "- **ERPCov + MDM**: ErpCovariance + MDM. A very simple, yet effective (for low channel count), Riemannian geometry classifier.\n",
    "\n",
    "Evaluation is done through cross-validation, with area-under-the-curve (AUC) as metric (AUC is probably the best metric for binary and unbalanced classification problem)\n",
    "\n",
    "*Note: because we're doing machine learning here, the following cell may take a while to complete*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "\n",
    "from pyriemann.estimation import ERPCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.spatialfilters import Xdawn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "clfs = OrderedDict()\n",
    "\n",
    "clfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "clfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(Xdawn(2, classes=[1]), Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['ERPCov + TS'] = make_pipeline(ERPCovariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(), MDM())\n",
    "\n",
    "# format data\n",
    "epochs.pick_types(eeg=True)\n",
    "X = epochs.get_data() * 1e6\n",
    "times = epochs.times\n",
    "y = epochs.events[:, -1]\n",
    "\n",
    "# define cross validation \n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "# run cross validation for each pipeline\n",
    "auc = []\n",
    "methods = []\n",
    "for m in clfs:\n",
    "    res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    auc.extend(res)\n",
    "    methods.extend([m]*len(res))\n",
    "    \n",
    "results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "results['Method'] = methods\n",
    "\n",
    "plt.figure(figsize=[8,4])\n",
    "sns.barplot(data=results, x='AUC', y='Method')\n",
    "plt.xlim(0.2, 0.85)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classifier for this dataset was ERP Covariance + MDM, which achieved an accuracy of around 0.77. This could be considered good enough for a BCI application, though one shouldn't expect outstanding results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Share your Data!\n",
    "\n",
    "How did your experiment go? If you're excited by your results we'd love to see your data!\n",
    "\n",
    "Follow the instructions on our [Contributions](https://github.com/NeuroTechX/eeg-notebooks/blob/master/CONTRIBUTING.md) page to make a pull request with your data and we'll review it to be added to the EEG notebooks project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "mne"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
